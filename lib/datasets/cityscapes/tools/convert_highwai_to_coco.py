'''
Utility to convert annotatations generated by Mindtech Chameleon HighWai
into COCO format.
Handles images placed in images dirs, enumerated in img_dirs list (see below)
and creates JSON files in COCO format placed at <outdir>.
HighWai data are expected to have structure (which is an output of HighWai):
\
|- annotations.haf.csv
|- images\
|       image_***.png
|       ....
|- masks\
|       mask_***.hmf
|       ....
'''
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import argparse
import json
import os
import sys
import csv
import cv2
import PIL.Image
import numpy as np

import utils.segms as segms_util
import utils.boxes as bboxs_util

# list of pairs
# (output annotation JSON file in COCO format (to be placed at <outdir>),
#  path to HighWai images from <datadir>)
img_dirs = [
    ('gen_IntersectionWithPedestrians', 'gen_IntersectionWithPedestrians/dataset/images'),
]

def parse_args():
    parser = argparse.ArgumentParser(description='Convert dataset')
    parser.add_argument(
        '--datadir', help="data dir for annotations to be converted",
        type=str, required=True)
    parser.add_argument(
        '--outdir', help="output dir for json files", type=str, required=True)
    return parser.parse_args()


def get_dict_with_polygons(root, filename, file_ext, width, height, instance_classes):

    #fullname = os.path.join(root, image['seg_file_name'])
    #box_fn = os.path.join('../boxes', '_'.join(['json'] + filename.split('_')[1:]) + '.json')
    mask_fn = os.path.join('../masks', '_'.join(['mask'] + filename.split('_')[1:]) + '.hmf')

    mask_data = np.flipud(np.fromfile(os.path.join(root, mask_fn), dtype=np.int32).reshape((height, width)))  # bottom based to topbased
    mask_data = np.array(mask_data)

    # Initialize label categories
    instances = []

    # Loop through all instance ids in instance image
    for instanceId in np.unique(mask_data):
        label_id = instance_classes.get((instanceId, filename+file_ext))
        if label_id is None:
            print('{0}: ignored instanceId {1}'.format(filename, instanceId))
            continue
        instanceObj_dict = {
            'instID'     : instanceId,
            'labelID'    : label_id,
        }

        mask = (mask_data == instanceId).astype(np.uint8)
        instanceObj_dict['pixelCount'] = int(np.sum(mask, dtype=np.int))

        contour, hier = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)
        polygons = [c.reshape(-1).tolist() for c in contour]
        instanceObj_dict['contours'] = polygons

        instances.append(instanceObj_dict)

    return instances


def convert(data_dir, out_dir):
    json_name = '%s.json'
    img_id = 0
    ann_id = 0
    category_dict = {
        'train': 1,
        'truck': 2,
        'rider': 3,
        'person': 4,
        'bus': 5,
        'motorcycle': 6,
        'bicycle': 7,
        'car': 8,
    }

    highwai_to_category = {
        'car': 'car',
        'truck': 'truck',
        'van': 'bus',
        'bus': 'bus',
        'motorcycle': 'motorcycle',
        'ambulance': 'bus',
        'firetruck': 'truck',
        'taxi': 'car',
        'train': 'train',
        'bicycle': 'bicycle',
        'pedestrian': 'person',
    }

    for data_set, img_dir in img_dirs:
        print('Starting {0}: {1}'.format(data_set, img_dir))
        ann_dict = {}
        images = []
        annotations = []
        img_dir = os.path.join(data_dir, img_dir)
        with open(os.path.join(img_dir, '../annotations.haf.csv'), newline='') as csvfile:
            reader = csv.reader(csvfile, delimiter=',')
            instance_classes = { (int(r[1]), r[21]): int(category_dict.get(highwai_to_category.get(r[6]))) for r in list(reader)[1:]}

        for root, _, files in os.walk(img_dir):
            for filename in files:
                filename, file_ext = os.path.splitext(filename)
                if file_ext == '.png':
                    if len(images) % 50 == 0:
                        print("Processed %s images, %s annotations" % (
                            len(images), len(annotations)))

                    image = {}
                    image['id'] = img_id
                    img_id += 1

                    img = PIL.Image.open(os.path.join(root, filename+file_ext))

                    image['width'] = img.width
                    image['height'] = img.height
                    image['file_name'] = filename + file_ext
                    images.append(image)

                    objects = get_dict_with_polygons(root, filename, file_ext, image['width'], image['height'], instance_classes)

                    for obj in objects:
                        if obj['contours'] == []:
                            print('Warning: empty contours.')
                            continue  # skip non-instance categories

                        len_p = [len(p) for p in obj['contours']]
                        if min(len_p) <= 1:
                            print('Warning: invalid contours.')
                            continue  # skip non-instance categories

                        ann = {}
                        ann['id'] = ann_id
                        ann_id += 1
                        ann['image_id'] = image['id']
                        ann['segmentation'] = obj['contours']

                        ann['category_id'] = obj['labelID']
                        ann['iscrowd'] = 0
                        ann['area'] = obj['pixelCount']
                        ann['bbox'] = bboxs_util.xyxy_to_xywh(
                            segms_util.polys_to_boxes(
                                [ann['segmentation']])).tolist()[0]

                        annotations.append(ann)

        ann_dict['images'] = images
        categories = [{"id": category_dict[name], "name": name} for name in category_dict]
        ann_dict['categories'] = categories
        ann_dict['annotations'] = annotations
        print("Num categories: %s" % len(categories))
        print("Num images: %s" % len(images))
        print("Num annotations: %s" % len(annotations))
        with open(os.path.join(out_dir, json_name % data_set), 'w') as outfile:
            outfile.write(json.dumps(ann_dict))


if __name__ == '__main__':
    args = parse_args()
    convert(args.datadir, args.outdir)
